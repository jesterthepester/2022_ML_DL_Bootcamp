{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WOw8yMd1VlnD"},"source":["# Data Preprocessing Template"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NvUGC8QQV6bV"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np # allows to use arrays\n","import pandas as pd # import data set and features\n","import matplotlib.pyplot as plt # allows for plotting of charts"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fhYaZ-ENV_c5"},"source":["## Importing the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# \"data.csv\" is the data we need\n","# country, age, wage, purchase\n","\n","dataset = pd.read_csv('Data.csv')\n","\n","# feature variable the first couple of columns\n","# dependant variable vector is the purchase column, the item we want to predict\n","\n","x = dataset.iloc[:, :-1].values # : represents range inc. all rows, second represents not the last column\n","y = dataset.iloc[:, -1].values # only want one column and thus you don't require a range"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 nan]\n"," ['France' 35.0 58000.0]\n"," ['Spain' nan 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}],"source":["print(x)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"]}],"source":["print(y) # End of lesson 1"]},{"cell_type":"markdown","metadata":{},"source":["## Taking care of missing data"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from sklearn.impute import SimpleImputer # tool for averaging values\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n","# nan values from the call to the csv file (non-existant values)\n","\n","imputer.fit(x[:, 1:3])\n","# which values are we doing this for?\n","\n","x[:, 1:3] = imputer.transform(x[:, 1:3])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[['France' 44.0 72000.0]\n"," ['Spain' 27.0 48000.0]\n"," ['Germany' 30.0 54000.0]\n"," ['Spain' 38.0 61000.0]\n"," ['Germany' 40.0 63777.77777777778]\n"," ['France' 35.0 58000.0]\n"," ['Spain' 38.77777777777778 52000.0]\n"," ['France' 48.0 79000.0]\n"," ['Germany' 50.0 83000.0]\n"," ['France' 37.0 67000.0]]\n"]}],"source":["print(x)"]},{"cell_type":"markdown","metadata":{},"source":["## Encoding Categorical Data"]},{"cell_type":"markdown","metadata":{},"source":["### Encoding Independent Variable"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# one hot encoding for the countries\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# variables\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])],remainder='passthrough')\n","x = np.array(ct.fit_transform(x))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [0.0 1.0 0.0 30.0 54000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 35.0 58000.0]\n"," [0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}],"source":["print(x)"]},{"cell_type":"markdown","metadata":{},"source":["### Encoding Dependent Variable"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","y = le.fit_transform(y)\n","# no np as it is the dependent variable"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 0 0 1 1 0 1 0 1]\n"]}],"source":["print(y)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3abSxRqvWEIB"},"source":["## Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 38.77777777777778 52000.0]\n"," [0.0 1.0 0.0 40.0 63777.77777777778]\n"," [1.0 0.0 0.0 44.0 72000.0]\n"," [0.0 0.0 1.0 38.0 61000.0]\n"," [0.0 0.0 1.0 27.0 48000.0]\n"," [1.0 0.0 0.0 48.0 79000.0]\n"," [0.0 1.0 0.0 50.0 83000.0]\n"," [1.0 0.0 0.0 35.0 58000.0]]\n"]}],"source":["print(X_train)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 1.0 0.0 30.0 54000.0]\n"," [1.0 0.0 0.0 37.0 67000.0]]\n"]}],"source":["print(X_test)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 0 0 1 1 0 1]\n"]}],"source":["print(Y_train)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1]\n"]}],"source":["print(Y_test)"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Scaling\n","**Standardisation vs normalisation** <br>\n","- std - values between -3 and 3<br>\n","- norm - 0 to 1 - most features following a standard deviation\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train[:,3:] = sc.fit_transform(X_train[:,3:])\n","X_test[:,3:] = sc.transform(X_test[:,3:],)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n"," [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n"," [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n"," [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n"," [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n"," [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n"," [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n"," [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"]}],"source":["print(X_train) # sometimes between +- 3 and sometimes between +-2"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n"," [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"]}],"source":["print(X_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOD2/gZgY69JdiiGJVNfu7s","collapsed_sections":[],"name":"data_preprocessing_template.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
